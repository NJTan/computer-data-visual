

# 京东电脑数据爬虫、可视化和决策树模型建立
[TOC]
## 摘要
   @(关键词)[爬虫，数据处理，数据可视化，决策树]
   本文主要是对京东的一个电脑的HTML页面利用通过python的urllib库进行爬虫，爬取京东电脑15页的数据，页面的属性包括电脑出售时电脑的基本信息、电脑所在的店铺、价格、评论数、好评数、中评数、差评数。通过去停用词、封装字典、去残缺值、利用箱图去异常值进行数据处理，然后将数据按照小米、华为、戴尔、联想、苹果、惠普、神舟、华硕这8大品牌对上面七种属性进行数据分析，并且对应的各种属性的数据可视化。最后通过按照8种电脑的品牌分类，利用决策树探究这8种电脑的影响因素，创建决策图。通过可视化可以实现推测未来电脑品牌流行趋势的目标，通过建立决策树模型实现向顾客推荐他/她喜欢的电脑品牌的目标。
##1. 爬取京东电脑数据
###1.1 数据来源
&nbsp &nbsp 电脑的商品的数据主要通过爬取https://list.jd.com/list.html?cat=670,671,672&page=页号的url的HTML页面的电脑数据，通过匹配每个html标签得到电脑、店铺、价格、评论数、好评数、中评数、差评数的值，每一页有60个电脑数据，通过爬取15页得到合适的数据。保存在xls文件中。命名为京东部分电脑销售以及评论数据。
###1.2 数据说明
&nbsp &nbsp 数据的类型包括字符串和数据类型，数据包含电脑，店铺，价格、好评数、中评数、差评数这7个属性。通过店铺可以得到该电脑是哪种电脑。根据评论数可以体现出电脑的销量，好评数、中评数、差评数体现出电脑的质量问题。
###1.3 数据预处理
&nbsp &nbsp因为爬虫会因为超时没有获取到某种的属性的信息，所以先将残缺的值赋值为0，因为只存在于店铺的信息会超时，所以0是适合的。然后利用fuzzywuzzy 库函数对店铺进行模糊匹配处理，得到不同品牌的电脑，异常值会影响对整体数据作可视化、建立分类模型的影响，所以使用盒图的原理将价格、评论数、好评数、中评数、差评数进行去异常值处理。
```
def e_value(e_data):
    perce=np.percentile(e_data,(25,50,75),interpolation='midpoint')
    Q1=perce[0]#上四分数
    Q3=perce[2]#下四分数
    IQR=Q3-Q1
    ulim=Q3+1.5*IQR
    llim=Q1-1.5*IQR
    return ulim,llim
```
```
nedata1=del_e_value(e_price_x,e_price_y,'价格',data2)
e_com_x,e_com_y=e_value(nedata1['评论数'])
newdata2=del_e_value(e_com_x,e_com_y,'评论数',nedata1)
e_good_x,e_good_y=e_value(newdata2['好评数'])
newdata3=del_e_value(e_good_x,e_good_y,'好评数',newdata2)
e_zong_x,e_zong_y=e_value(newdata3['中评数'])
newdata3=del_e_value(e_zong_x,e_zong_y,'中评数',newdata3)
e_poor_x,e_poor_y=e_value(newdata3['差评数'])
data2=del_e_value(e_poor_x,e_poor_y,'差评数',newdata3)

```
预处理完的数据保存在“筛选后的数据.xls"
##2. 数据可视化
&nbsp &nbsp 数据可视化的目标是为了推测8种品牌的电脑的未来趋势，同时探究各种属性的特点，对这8种电脑销量的影响。
###2.1 数据处理和处理方法
&nbsp &nbsp根据探究不同属性，进行不同的可视化对数据进行再处理的操作。
- 饼图和盒图
  - 对店铺数据进行模糊匹配得到8种电脑在京东上的分布，利用饼图将分布展现出来，并且保存在相应的数据中
  - 盒图：需要先对数据进行去异常值处理
- 词云
  - 词云是对每家商店对电脑销售的一串文字信息进行分析，因为包含特殊的符号，所以需要使用去停用词处理过滤点不影响结果的符号，然后就使用workcloud画词云，需要添加encoding='utf-8'
  -  利用一张背景图，将出现次数来决定字体的大小，然后按背景图描绘轮廓得出来。
- 密度图、散点图和小提琴图
首先按照在数据中添加品牌类型一列，使用的是dataFrame增加列的方法，直接在原有的类型基础上增加data['品牌']，然后保存在"添加后的数据.xls"中
 - 密度图
   - 将8中品牌的电脑放在4*2的子图中，使用subplot()
   - 图片的图例和名字显示出来
 - 散点图
   - 列出基于品牌价格、好评、差评的散点图
 - 小提琴图
   - 基于散点图的基础上，列出基于品牌的价格、好评、差评的内涵散点图的小提琴图

###2.2.饼图和盒图
####2.2.1 饼图
![](https://upload-images.jianshu.io/upload_images/16151758-fd2fa043d781779e.png)
&nbsp &nbsp 由此可见，京东中联想品牌的商店分布量是比较多的，可以得知联想在京东的竞争比较大，神舟和华为次之，小米的商店是比较少的，这也符合小米饥饿出售的原则。
####2.2.2 盒图
&nbsp &nbsp 下面的每一张盒图都是经过去除异常值的，有少量异常值是保留下来。绿色的点表示平均值，中间的线表示中位数
![](https://upload-images.jianshu.io/upload_images/16151758-a67fe44976a879ec.png)
&nbsp &nbsp 评论数的盒图反映了大部分的商家出售电脑的数量是达到了10000台以上，
![](https://upload-images.jianshu.io/upload_images/16151758-267f8aaead0b89a0.png)
&nbsp &nbsp 这张盒图反映了价格与好评数的中位数，在价格中平均数和中位数持平，说明有一半的电脑的价格都是5000以上的
好评数中说明电脑的质量还是相对来说有保证，好评数的平均数为大约5000.
![](https://upload-images.jianshu.io/upload_images/16151758-8792c3341e7aa782.png)
&nbsp &nbsp 这张盒图主要反映中评数和差评数，由此可见，中评数与差评数相对于好评数来说是比较少的，也就是人们对于在京东上买电脑的不满意度是不大的，京东上买电脑的还是比较能接受的。
###2.3.词云
####2.3.1 作用效果、
![](https://upload-images.jianshu.io/upload_images/16151758-be8f584116fe4ead.png)
####2.3.2 反映内涵
&nbsp &nbsp 商家通过抓取人们眼球，会将人们比较关注得信息放在电脑介绍的文字信息中。通过词云图可知主题是笔记本电脑，然后人们比较喜欢的电脑类型的特点是：轻薄、酷睿；考虑的电脑的性能特点有商务类、办公类、游戏本、独显、英特尔。
###2.4.密度图、散点图和小提琴图
####2.4.1 密度图
图片中黄色的那条线刻画了在这条价格的稀疏程度，于条形图的作用效果类似。
![](https://upload-images.jianshu.io/upload_images/16151758-96d416af20e105d3.png)
&nbsp &nbsp 小米的价格主要价格主要分布在4000到5000，相对来说还是比较惠民的，因为满足上面平均数是5000的范围之内，分布比较集中。
&nbsp &nbsp 华为的价格相对来说价格分布比较稀疏，，但是也是相对比较便宜的一种电脑，大部分分布在3000到6000的价格范围内。
&nbsp &nbsp联想、神舟、戴尔的价格分布类似，密度集中度仅此小米，大部分价格分布在4000到6000左右。
&nbsp &nbsp华硕的电脑集中度排第三，价格集中在5000到6000。
&nbsp &nbsp 苹果的电脑最贵，在8000到15000左右，且集中度高。
####2.4.2 散点图
![](https://upload-images.jianshu.io/upload_images/16151758-7b9d80b30c094f16.png)
![](https://upload-images.jianshu.io/upload_images/16151758-90ab1d3be6682a73.png)
![](https://upload-images.jianshu.io/upload_images/16151758-91002c8108d16f32.png)
&nbsp&nbsp根据上面三张散点图可以得知无论是价格集中分布在中游4000到6000，苹果是比较贵的。好评数是集中在中下游5000左右，华为和联想的好评数有一部分集中分布在15000，所以华为和联想的好评是比较多的。差评的话大部分集中分布在0到100以内，相对来说戴尔的差评数在300以上比较多，所以戴尔的风评在京东上不是太友好。
####2.4.3 小提琴图
![](https://upload-images.jianshu.io/upload_images/16151758-5601ceb427572758.png)
![](https://upload-images.jianshu.io/upload_images/16151758-13cb97b12a232d6c.png)
![](https://upload-images.jianshu.io/upload_images/16151758-d8b03c5af54f83c8.png)
![](https://upload-images.jianshu.io/upload_images/16151758-c5ea05d6558381b8.png)
&nbsp&nbsp通过上面四张图来看，华为和戴尔在价格上、评论数、好评数是类似，都是比较便宜、好评相对多，但是戴尔的差评比华为更多一些。
&nbsp&nbsp 联想、惠普、神舟在价格、好评、差评都是比较集中分布在底层的，所以是比较便宜，销量一般，好评好，差评少。
&nbsp&nbsp 华硕是比较稀疏的，哪个区域排布相等，价格是排在中下游的。
&nbsp&nbsp 小米是比较像小提琴的，它的价格排布集中在中下游，销量中上游，总体不错。

##3. 决策树分类模型建立
###3.1. 数据处理
&nbsp&nbsp首先因为是为了实现根据店铺数量、价格、评论数、好评数、差评数、中评数等属性来得出推荐人们喜欢什么类型的电脑。得出准确率。所以需要探究哪种因素影响比较大，去掉没有影响的因素，因为数据中含有其他的类型，所以先数据按照8中品牌分类，删去其他电脑的数据，其次，需要计算各个店铺的数量，作为店铺的一种变量，叫做店铺数量，保存在"knnClass.xls"
&nbsp&nbsp 为了方便分类，使用map将品牌类型映射为数字
```
 computerData['品牌']=computerData['品牌'].map({
      '华为':0,'联想':1,'神舟':2,'华硕':3,'戴尔':4,'苹果':5,'惠普':6,
      '小米':7
   })
```
   
###3.2.建立决策树模型
&nbsp&nbsp因为一开始不知道使用哪种模型，所以尝试了高斯分类模型、回归模型、knn分类模型得出的准确率不如决策树，于是决定用决策树进行建模。然后刚开始尝试探究单一变量对于分类的影响,最后得出了决定人们想要买什么类型的电脑是由店铺的数量、价格、评论数、好评数、差评数相关的
- 首先将数据集按照6：4的比例分成训练集和测试集
```
x=df_data[['店铺数量','价格','评论数', '好评数','差评数']]
   y=df_data['品牌']
   #按照8：2的比例随机分为训练集，测试集
   x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4)
```
- 然后建立决策树模型，并计算准确率,准确率集中在0.7999到93.000之间，相对来说比较准确的
```
   de=DecisionTreeClassifier(random_state=2019)
   de.fit(x_train,y_train)
   y_pred=de.predict(x_test)
   print(len(y_pred))
   print('Test set predictions:\n{}'.format(y_pred))
   #用测试集评估模型的好坏
   print('决策树准确率：',de.score(x_test,y_test))
   #决策树准确率： 0.8220858895705522
   #如果不要店铺数量
   决策树准确率： 0.6134969325153374
```
- 对模型进行评估
```
  ####模型评估###
   con_m=confusion_matrix(y_test,y_pred)
   df_con_m=pd.DataFrame(con_m,columns=computerClass,index=computerClass)
   df_con_m.index.name='真实值'
   df_con_m.columns.name='预测值'
   print(df_con_m)
#  预测值  小米  联想  华硕  戴尔  华为  神舟  惠普  苹果
真实值                                
小米    0   0   1   0   0   0   0   0
联想    0  36   0   3   0   0   1   2
华硕    1   0  14   0   4   0   1   0
戴尔    1   0   3  17   2   0   5   0
华为    0   0   1   0  22   0   0   0
神舟    0   0   0   0   0  16   0   0
惠普    0   3   0   1   0   0  27   0
苹果    0   0   0   0   0   0   0   2
```
在进行混淆矩阵评估中我们知道行表示真实值，列表示预测值，可知，在此次分类中小米预测是不正确的，对角线上表示正确的，不在对角线上是预测错误分类的
###3.3.画出决策图
```
  dot_data=export_graphviz(de, max_depth=5, feature_names=['shopNums','prices','comments', 'GoodComments','poorComments'], class_names=['0','1','2','3','4','5','6','7'], filled=True, rounded=True,  special_characters=True)
   # 通过pydotplus将决策树规则解析为图形
   graph = py.graph_from_dot_data(dot_data)
   # 将决策树规则保存为PDF文件
   graph.write_pdf('tree.pdf')
   # 保存为jpg图片
   graph.write_jpg('juece.jpg')
```
![](https://upload-images.jianshu.io/upload_images/16151758-aed1b2740ab015e1.jpg)
不要店铺数量决策树
![](https://upload-images.jianshu.io/upload_images/16151758-683a2077e0127fe8.jpg)
&nbsp&nbsp 根据总体可知如果知道人们进去浏览哪一家店铺基本上就确定想要买什么电脑，在这个基础上考虑评论数，好评数和差评数能够有大概84.5%以上知道人们喜欢什么电脑，所以可以通过记录人们浏览过的店铺推送相对应类型的电脑
&nbsp&nbsp 因为京东上没有直接统计店铺类型的电脑的，所以可以通过好评数、差评数、评论数、价格来推荐什么类型的电脑，但是准确率不高，所以最终采取先统计店铺的数量，来得出买什么类型的电脑。
##4.总结
###4.1. 困难与解决方案
&nbsp&nbsp 首先爬虫自己没有学过，我自己找了一本关于爬虫入门的书，然后学会了爬取页面html的信息，爬虫部分的思想有参考网上的资料，然后自己补充了爬取15页的信息，以及好评数、中评数、差评数的一些变量。
&nbsp&nbsp python的基础知识是通过老师的讲授，学习了一些关于列表的增删改查，还有查看shape,以及如何使用dataFrame的一些操作，可视化通过老师推荐seaborn库实现的，为了更好的使用文件、保存图片、使用seaborn，我自己阅读两本关于数据可视化的书，其中一本重点是讲授python的基础语法知识，另一本是讲授matplotlib库的知识的。
&nbsp&nbsp 在数据处理的过程中遇到的困难是去异常值，通过查看盒图，自己知道如何弃掉异常值
&nbsp&nbsp plt.saveFig()生成空白的图片问题，自己是先保存，后plt.show()的
&nbsp&nbsp 词云中停用词处理和中文文本处理是查找网上资料实现的。
&nbsp&nbsp 关于决策树中文乱码问题，自己查找了很多网上资料的解决办法都没能解决，因为graphviz库是不支持中文的，所以最后采用了有字符映射类别。然后影响因素采用英文表示。
###4.2. 学习心得
&nbsp&nbsp 通过本次课题学习自己学会了如何爬取一个html页面，遇到困难的时候如何通过查阅资料来解决困难。自己觉得比较有成就感的是学会python的基础语法，同时学会了python的文件的读写操作方法，同时在这次学习中使用到了老师平时讲授的一些知识的，因为一切理论忠于实践。感谢老师对于基础知识的详细讲解。
&nbsp&nbsp 通过这次的课题学习更好的了解如何对数据进行合理的可视化分析，不适合的图可能会影响分析。也理解了决策树分类模型的内涵，可以知道哪种因素起到决定作用。
&nbsp&nbsp 同时自己需要改进的不足之处呢，就是可能代码编写的综合性不高，就是有一些代码应该进行更高更合理的封装，使得代码的重用性增大。
###4.3. 未来展望
&nbsp&nbsp 针对自己对于python的认识、爬虫知识的知识是初步性的认识，为了更好的进行可视化分析，我以后需要多作一些类似的课题积累可视化的经验。然后巩固python的知识点，在此基础上对爬虫进行深度的学习
&nbsp&nbsp 同时自己对于深度学习的知识认识不够，需要学习神经网络的相关知识，自己建立分类模型算法，这方面需要多做一些实践
&nbsp&nbsp 最后就是希望自己能够在可视化的道路上越走越好。

#参考文献

[1] 颛清山（译）.Python 数据可视化编程实战[M]第2版.北京：人民邮电出版社，2018.9
[2] 韦玮.精通Python网络爬虫[M].北京：机械工业出版社，2017.2
[3] Fabio Nelli著，杜春晓译[M].北京：人民邮电出版社，2016.8
[4][ 网络爬虫---用urllib模块爬取京东笔记本电脑的数据、并对其做一个可视化,2019.4](https://blog.csdn.net/qq_43546676/article/details/89071198)

